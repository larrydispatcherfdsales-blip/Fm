name: FMCSA Post Merge

permissions:
  contents: write   # push CSV

on:
  workflow_run:
    workflows: ["FMCSA Extractor (Single Batch)"]  # extractor workflow name
    types:
      - completed

jobs:
  process:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install pandas requests

      - name: Download & Merge Artifacts
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'EOF'
          import os, requests, zipfile, glob
          from io import BytesIO
          import pandas as pd

          repo = os.getenv("GITHUB_REPOSITORY")
          token = os.getenv("GITHUB_TOKEN")
          headers = {"Authorization": f"token {token}"}

          # ---------- STEP 1: Download Artifacts ----------
          runs_url = f"https://api.github.com/repos/{repo}/actions/runs?per_page=50"
          runs = requests.get(runs_url, headers=headers).json().get("workflow_runs", [])

          os.makedirs("artifacts", exist_ok=True)
          csv_files = []

          for run in runs:
              if run["name"] == "FMCSA Extractor (Single Batch)":
                  artifacts_url = run["artifacts_url"]
                  artifacts = requests.get(artifacts_url, headers=headers).json().get("artifacts", [])
                  for art in artifacts:
                      dl_url = art["archive_download_url"]
                      r = requests.get(dl_url, headers=headers)
                      with zipfile.ZipFile(BytesIO(r.content)) as zf:
                          zf.extractall("artifacts")
                          for f in zf.namelist():
                              if f.endswith(".csv"):
                                  csv_files.append(os.path.join("artifacts", f))

          print(f"✅ Downloaded {len(csv_files)} CSV files")

          # ---------- STEP 2: Merge CSVs ----------
          merged_rows = []
          for file in glob.glob("artifacts/**/*.csv", recursive=True):
              try:
                  df = pd.read_csv(file)
                  merged_rows.append(df)
              except Exception as e:
                  print(f"❌ Failed to read {file}: {e}")

          if merged_rows:
              final_df = pd.concat(merged_rows, ignore_index=True)
              final_df.drop_duplicates(inplace=True)
              os.makedirs("outbox", exist_ok=True)
              final_df.to_csv("outbox/merged_fmcsa.csv", index=False)
              print(f"✅ Final merged CSV with {len(final_df)} rows")
          else:
              print("⚠ No CSVs merged")
          EOF

      - name: Commit & Push merged file
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add outbox/merged_fmcsa.csv
          git commit -m "Post-merge FMCSA CSV" || echo "No changes to commit"
          git pull --rebase https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git main
          git push https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git HEAD:main
