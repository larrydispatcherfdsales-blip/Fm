# ===== fmcsa-post-merge.yml (Updated) =====
name: FMCSA Post Merge

on:
  workflow_dispatch:

jobs:
  process:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install pandas requests

      - name: Download & Merge All Artifacts
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'EOF'
          import os, requests, zipfile, glob
          from io import BytesIO
          import pandas as pd

          repo = os.getenv("GITHUB_REPOSITORY")
          token = os.getenv("GITHUB_TOKEN")
          headers = {"Authorization": f"token {token}"}

          # === YEH LINE THEEK KI GAYI HAI ===
          # Pehle yahan workflow ka display name tha, ab file ka naam hai
          runs_url = f"https://api.github.com/repos/{repo}/actions/workflows/extractor.yml/runs?status=completed&per_page=100"
          
          runs_response = requests.get(runs_url, headers=headers )
          if runs_response.status_code != 200:
              print(f"❌ Failed to fetch workflow runs. Status: {runs_response.status_code}, Response: {runs_response.text}")
              runs = []
          else:
              runs = runs_response.json().get("workflow_runs", [])

          os.makedirs("artifacts", exist_ok=True)
          downloaded_artifacts = 0

          print(f"Found {len(runs)} completed runs for the extractor workflow.")

          for run in runs:
              artifacts_url = run["artifacts_url"]
              artifacts_response = requests.get(artifacts_url, headers=headers)
              if artifacts_response.status_code != 200:
                  print(f"❌ Failed to fetch artifacts for run ID {run['id']}.")
                  continue
              
              artifacts = artifacts_response.json().get("artifacts", [])
              for art in artifacts:
                  if "fmcsa-output-batch" in art["name"]:
                      print(f"Downloading artifact: {art['name']} from run ID {run['id']}")
                      dl_url = art["archive_download_url"]
                      r = requests.get(dl_url, headers=headers, timeout=60)
                      if r.status_code == 200:
                          try:
                              with zipfile.ZipFile(BytesIO(r.content)) as zf:
                                  zf.extractall("artifacts")
                                  downloaded_artifacts += 1
                          except zipfile.BadZipFile:
                              print(f"❌ Bad ZIP file for artifact {art['name']}.")
                      else:
                          print(f"❌ Failed to download artifact {art['name']}. Status: {r.status_code}")

          print(f"✅ Downloaded {downloaded_artifacts} artifacts.")

          all_dfs = []
          csv_files = glob.glob("artifacts/**/*.csv", recursive=True)
          print(f"Found {len(csv_files)} CSV files to merge.")

          for file in csv_files:
              try:
                  df = pd.read_csv(file)
                  if not df.empty:
                      all_dfs.append(df)
              except Exception as e:
                  print(f"❌ Failed to read or process {file}: {e}")

          if all_dfs:
              final_df = pd.concat(all_dfs, ignore_index=True)
              print(f"Total rows before dropping duplicates: {len(final_df)}")
              final_df.drop_duplicates(subset=['email', 'mcNumber'], keep='first', inplace=True)
              print(f"Total rows after dropping duplicates: {len(final_df)}")
              
              os.makedirs("output", exist_ok=True)
              final_df.to_csv("output/merged_fmcsa_data.csv", index=False)
              print(f"✅ Final merged CSV created with {len(final_df)} unique rows.")
          else:
              print("⚠️ No data found in any CSVs. Creating an empty placeholder file.")
              os.makedirs("output", exist_ok=True)
              with open("output/merged_fmcsa_data.csv", "w") as f:
                  f.write("email,mcNumber,phone,url\n")
          EOF

      - name: Commit & Push merged file
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add output/merged_fmcsa_data.csv
          git commit -m "chore: Update merged FMCSA data" || echo "No changes to commit"
          git push

      - name: Trigger Cleanup
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Triggering cleanup workflow..."
          gh workflow run cleanup.yml --ref main
